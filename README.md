YouTube Reasoning Prompt Dataset
A full pipeline: transcript extraction â†’ prompt generation â†’ golden answers â†’ evaluation â†’ dataset packaging â†’ Streamlit UI
This project builds a full reasoning dataset from YouTube videos, using transcripts + Gemini-generated prompts, golden answers, model evaluations, and a Streamlit browser.
ğŸš€ Features
1ï¸âƒ£ Transcript Extraction (yt-dlp)

Supports all subtitle formats: vtt, srt, json3, srv1-3, ttml, xml.
Parses into clean segments.
Extracts metadata (title, channel, upload date, duration, views, tags, etc.).

2ï¸âƒ£ Prompt Generation (Gemini 2.5 Flash)

Generates 3â€“5 multi-step reasoning prompts.
Adds domain + difficulty + golden-answer guidance.

3ï¸âƒ£ Golden Answer Generation

Produces high-quality ground-truth answers for each prompt.

4ï¸âƒ£ Evaluation System

Gemini 2.5 Flash answers each prompt.
Retry loops + self-correction logic.
Scores:
reasoning depth
factual accuracy
coherence


5ï¸âƒ£ Dataset Packaging
Folder structure:
textdataset/<VIDEO_ID>/
  transcript.json
  prompts.json
  golden_answers.jsonl
  model_outputs.jsonl
  results.csv
Also generates:

dataset/manifest.json

6ï¸âƒ£ Streamlit Dataset Viewer
Interactive UI to inspect:

transcripts
prompts
golden answers
evaluated model responses
scoring tables

ğŸ“‚ Project Structure
textyoutube-reasoning-prompt-dataset/
â”œâ”€ data/raw/
â”œâ”€ prompts/
â”œâ”€ models_outputs/
â”œâ”€ dataset/
â”‚   â””â”€ manifest.json
â”œâ”€ streamlit_app/
â”‚   â””â”€ app.py
â”œâ”€ src/
â”‚   â”œâ”€ collectors/
â”‚   â”‚   â””â”€ yt_dlp_collector.py
â”‚   â”œâ”€ generation/
â”‚   â”‚   â”œâ”€ prompt_generator.py
â”‚   â”‚   â””â”€ golden_answer_generator.py
â”‚   â”œâ”€ evaluation/
â”‚   â”‚   â””â”€ evaluator.py
â”‚   â”œâ”€ dataset/
â”‚   â”‚   â””â”€ build_dataset.py
â”‚   â”œâ”€ cli.py
â”‚   â””â”€ config.py
â””â”€ README.md
ğŸ› ï¸ Installation

Clone repotextgit clone https://github.com/YOUR_USERNAME/youtube-reasoning-prompt-dataset.git
cd youtube-reasoning-prompt-dataset
Create virtual environmenttextpython -m venv vir
vir\Scripts\activate      # Windows
Install dependenciestextpip install -r requirements.txt
Set your Gemini API key
Create .env:textGOOGLE_API_KEY=your_api_key_here

ğŸ“Œ Usage Guide
Phase 1 â€” Transcript Collection
textpython -m src.cli --collect-yt https://www.youtube.com/watch?v=dQw4w9WgXcQ
Phase 2 â€” Prompt Generation
textpython -m src.cli --gen-prompts dQw4w9WgXcQ --gen-model gemini-2.5-flash
Phase 3 â€” Generate Golden Answers
textpython -m src.generation.golden_answer_generator --video-id dQw4w9WgXcQ
Phase 4 â€” Evaluate Prompt Responses
textpython -m src.evaluation.evaluator --video-id dQw4w9WgXcQ --model gemini-2.5-flash --max-attempts 3
Phase 5 â€” Build Final Dataset
textpython -m src.dataset.build_dataset --video-id dQw4w9WgXcQ
ğŸ¨ Streamlit Viewer
Run locally
textstreamlit run streamlit_app/app.py
This opens a dashboard showing:

transcript
prompts
golden answers
model outputs
scoring metrics

ğŸŒ Deployment (Streamlit Cloud)

Push your repo to GitHub
Go to: https://share.streamlit.io
Select your repository
Set entrypoint: streamlit_app/app.py
Add environment variable: GOOGLE_API_KEY

Your dataset viewer goes live instantly.
ğŸ“¦ Example Dataset
A sample dataset is already included under:
textdataset/<VIDEO_ID>/
